{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window Functions\n",
    "\n",
    "In this notebook we'll introduce window functions, which are a powerful tool for working with data in SQL.\n",
    "\n",
    "Window functions in PySpark (and in SQL in general) are a tool for performing complex analytical tasks within PySpark DataFrames. They allow you to perform **calculations across a group of rows related to the current row, without aggregating the entire dataset**. This makes them very useful for tasks like calculating moving averages, ranking items within groups, and calculating cumulative sums.\n",
    "\n",
    "**Window functions allow you to calculate aggregate functions (like sum, average, max, min) over a specific window of rows**.\n",
    "\n",
    "Also, using window functions can be more efficient than traditional group by aggregations, especially when you want to include aggregated values alongside individual rows without reducing the number of rows.\n",
    "\n",
    "In this section, we're going to explore the main PySpark window functions. Let's start by downloading a dummy dataset of employees and load it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "\n",
    "wget https://raw.githubusercontent.com/inesmcm26/lp-big-data/main/data/employees.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees = (\n",
    "    spark.read.format('csv')\n",
    "    .option('inferSchema', 'true')\n",
    "    .option('header', 'true')\n",
    "    .option('sep', ',')\n",
    "    .load('file:/databricks/driver/employees.csv')\n",
    ")\n",
    "\n",
    "df_employees.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Window functions, we first need to define a `Window`. This class is part of the PySpark SQL library and allows you to perform calculations across a group of rows related to one another. [Here](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Window.html) you can find the official documentation of this class.\n",
    "\n",
    "It has three main methods:\n",
    "\n",
    "- `partitionBy(col/cols)`: Partitioning is the process of dividing the dataset into groups of rows based on some criteria. This method is used to define these partitions.\n",
    "- `orderBy(col/cols)`: This method defines the order in which rows within each partition are processed. If no partition is defined, the whole dataset is considered.\n",
    "- `rowsBetween(start, end)`: Defines the range of rows included in a window frame for window functions. For each row, the window function will only consider the rows within the specified window range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation functions\n",
    "\n",
    "We've seen some aggregation function in the previous module. These were used to aggregate the values resulting from a `groupBy` operation.\n",
    "\n",
    "However, these functions can also be used with Window operations.\n",
    "\n",
    "Let's answer some questions to exemplify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each employee, what is the average salary in their department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define our Window object.\n",
    "# We want to partition by 'department'\n",
    "window = Window.partitionBy('department')\n",
    "\n",
    "# Next we define an aggregation function over the window\n",
    "avg_salary_fn = f.avg(f.col('salary')).over(window)\n",
    "\n",
    "# To get the result we need to apply the window function to a dataframe\n",
    "# To do that, we create a new column with the result of the window function\n",
    "df_employees.withColumn('avg_salary_department', avg_salary_fn).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For each employee, what is the maximum salary in their department?\n",
    "\n",
    "We have two ways of answering this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Partition by department\n",
    "window = Window.partitionBy('department')\n",
    "\n",
    "# Define the `max` aggregation function\n",
    "max_salary_fn = f.max('salary').over(window)\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_employees.withColumn('max_salary_department', max_salary_fn).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Partition by department and order the salary values in descending\n",
    "# order within each Window frame\n",
    "window = Window.partitionBy('department').orderBy(f.desc('salary'))\n",
    "\n",
    "# Define the `first` aggregation function to get the first salary\n",
    "# in each window frame\n",
    "max_salary_fn = f.first('salary').over(window)\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_employees.withColumn('max_salary_department', max_salary_fn).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For each employee, what is the average salary per gender in their department?\n",
    "\n",
    "We can also partition the dataset using more than 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define our Window object.\n",
    "# We want to partition by 'department' and 'gender'\n",
    "window = Window.partitionBy(['department', 'gender'])\n",
    "\n",
    "# Next we apply an aggregation fucntion over the window\n",
    "avg_salary_fn = f.avg(f.col('salary')).over(window)\n",
    "\n",
    "# To get the result from the window function we need to apply it to a dataframe\n",
    "df_employees.withColumn('avg_salary_sex_department', avg_salary_fn).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know what you're thinking. The way we answered these questions is very similar to using a `groupBy` operation. In fact, in questions ***1*** and ***2***, for instance, all employees from the same department have the same aggregated value.\n",
    "\n",
    "So, why use window functions? Mainly because the questions started with 'For each employee...', which makes it useful to have a new column with the aggregated value for each employee.\n",
    "\n",
    "If, for example, question ***1*** was 'What is the average salary in each department?', then a `groupBy` operation would be enough.\n",
    "\n",
    "\n",
    "As you can see, sometimes it might be useful to maintain the dataset shape as is. Window functions enable you to compute aggregated values alongside detailed information from other columns in the dataset. This allows for more complex analyses and reporting scenarios where you need both aggregated summaries and detailed information.\n",
    "\n",
    "Let's see a more complex example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Imagine you want to calculate the difference between each employee's salary and the average salary of the five employees closest in salary, including the employee itself (two with higher salaries and two with lower salaries)\n",
    "\n",
    "Let's break this question down:\n",
    "- We want to calculate the difference between each employee's salary and an average salary\n",
    "- The average salary should be calculated considering only 5 employees' salaries\n",
    "- These 5 employees are the two above in terms of salary order, the two below, and the employee himself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window with a limited size: between the 2 before and 2 after rows\n",
    "window = Window.orderBy(f.desc('salary')).rowsBetween(-2, 2)\n",
    "\n",
    "(\n",
    "    df_employees\n",
    "    .withColumn(\n",
    "        'avg_salary',\n",
    "        # Apply the aggregation function to the limited window\n",
    "        f.avg('salary').over(window)\n",
    "    )\n",
    "    .withColumn(\n",
    "        'salary_diff',\n",
    "        f.col('salary') - f.col('avg_salary')\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row function\n",
    "\n",
    "Besides aggregation functions, we can also apply the `row_number()` function over a window.\n",
    "\n",
    "This function assigns a unique sequential integer to each row within a partition, according to the order in which the rows appear in the partition. The first row gets the number 1, the second row gets the number 2, and so on.\n",
    "\n",
    "Let's rank the employees by salary in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a window ordered by 'salary'\n",
    "# Since this window is not partitioned, the whole dataset is used for sorting\n",
    "window = Window.orderBy(f.desc('salary'))\n",
    "\n",
    "# Apply the `row_number` window function to the dataset\n",
    "# over the defined window\n",
    "(\n",
    "    df_employees\n",
    "    .withColumn('row_number', f.row_number().over(window))\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank function\n",
    "\n",
    "The `rank()` function is similar to the `row_number()` function, but it does not assign a unique sequential integer to each row. Instead, it assigns the same rank to rows with the same value.\n",
    "\n",
    "Let's rank the employees by salary in descending order using the `rank()` function and compare the results with the `row_number()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a window ordered by 'salary'\n",
    "# Since this window is not partitioned, the whole dataset is used for sorting\n",
    "window = Window.orderBy(f.desc('salary'))\n",
    "\n",
    "# Apply the `rank` window function to the dataset\n",
    "# over the defined window\n",
    "(\n",
    "    df_employees\n",
    "    .withColumn('row_number', f.rank().over(window))\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the difference? Jessica and Ivy got the same rank because they have the same salary.\n",
    "\n",
    "Now let's apply the `rank()` to find the salary ranking by gender.\n",
    "\n",
    "This time, the rank will be calculated for each partition of the column `gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy('gender').orderBy(f.desc('salary'))\n",
    "\n",
    "(\n",
    "    df_employees\n",
    "    .withColumn('salary_rank', f.rank().over(window))\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Rank Function\n",
    "\n",
    "This function works similarly to the `rank()` function, but it does not leave gaps between consecutive ranks. If two rows have the same value, they will receive the same rank, and the next row will receive the next rank available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy('gender').orderBy(f.desc('salary'))\n",
    "\n",
    "(\n",
    "    df_employees\n",
    "    .withColumn('salary_rank', f.dense_rank().over(window))\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead and Lag Functions\n",
    "\n",
    "Lead and lag are functions that are applied to each dataset row, within a window partition.\n",
    "\n",
    "Lead returns the value of a column at a specified offset after the current row.\n",
    "Lag returns the value of a column at a specified offset before the current row.\n",
    "\n",
    "Let's look at the salary difference between employees within a department. We want to quantify the salary difference between each employee and the next employee earning more within the same department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window\n",
    "window = Window.partitionBy('department').orderBy('salary')\n",
    "\n",
    "(\n",
    "    df_employees\n",
    "    .withColumn('next_salary', f.lead(col=f.col('salary'), offset=1).over(window))\n",
    "    .withColumn(\n",
    "        'salary_diff',\n",
    "        f.col('next_salary') - f.col('salary')\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do the reverse operation and see how much more each employee earns compared to the next employee earning less within the same department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window\n",
    "window = Window.partitionBy('department').orderBy('salary')\n",
    "\n",
    "(\n",
    "    df_employees\n",
    "    .withColumn('prev_salary', f.lag(col=f.col('salary'), offset=1).over(window))\n",
    "    .withColumn(\n",
    "        'salary_diff',\n",
    "        f.col('salary') - f.col('prev_salary')\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now that you know how to use the main window functions, go to the `exercises` notebook and practice what you've learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Now that you know how to use the main window functions, let's get back to our orders dataset and practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"/FileStore/lp-big-data/preprocessed-data/orders-data/orders_preprocessed.csv\")\n",
    ")\n",
    "\n",
    "df_products = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .load(\"/FileStore/lp-big-data/preprocessed-data/orders-data/products_preprocessed.csv\")\n",
    ")\n",
    "\n",
    "df_orders_products = (\n",
    "    df_orders.join(\n",
    "        df_products,\n",
    "        on=['product_id'],\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "df_orders_products.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rank each customer based on the total amount of ordered products.\n",
    "\n",
    "The ranking should have no gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the total amount of ordered products by customer\n",
    "df_total_amount = (\n",
    "    df_orders_products\n",
    "    .groupBy('customer_id')\n",
    "    .agg(f.sum('amount').alias('total_amount'))\n",
    ")\n",
    "\n",
    "df_total_amount.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window ordered by 'total_amount' in descending order\n",
    "window = Window.orderBy(f.desc('total_amount'))\n",
    "\n",
    "(\n",
    "    df_total_amount\n",
    "    # Rank the customers by their total amount of ordered products\n",
    "    .withColumn('customer_rank', f.dense_rank().over(window))\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For each order, what is the difference in days between the current order's placing date and the last order's placing date for the same customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window: partition by 'customer_id' and order by 'placing_date'\n",
    "window = Window.partitionBy('customer_id').orderBy('placing_date')\n",
    "\n",
    "(\n",
    "    df_orders_products\n",
    "    # Get the previous order date for each order\n",
    "    .withColumn(\n",
    "        'prev_order_date',\n",
    "        f.lag('placing_date').over(window)\n",
    "    )\n",
    "    # Calculate the difference in days between the current and previous order\n",
    "    .withColumn(\n",
    "        'days_diff',\n",
    "        f.datediff(\n",
    "            f.col('placing_date'),\n",
    "            f.col('prev_order_date')\n",
    "        )\n",
    "    )\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'order_id',\n",
    "        'placing_date',\n",
    "        'prev_order_date',\n",
    "        'days_diff'\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For each customer, what is the difference in revenue between each of his orders and the average revenue of the previous three placed orders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window: partition by 'customer_id', order by 'placing_date' and select the last 3 rows\n",
    "window = Window.partitionBy('customer_id').orderBy('placing_date').rowsBetween(-3, 0)\n",
    "\n",
    "(\n",
    "    df_orders_products\n",
    "    # Calculate the average revenue for the last 3 orders\n",
    "    .withColumn(\n",
    "        'avg_revenue',\n",
    "        f.avg('revenue').over(window)\n",
    "    )\n",
    "    # Calculate the difference between the total price and the average revenue\n",
    "    .withColumn(\n",
    "        'revenue_diff',\n",
    "        f.col('revenue') - f.col('avg_revenue')\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For each customer, what is the absolute difference in days between each of his order's delivery date and the next order's placing date, where the next order's placing date is before than the current order's delivery date?\n",
    "\n",
    "Let's break the question down:\n",
    "- We want to calculate the difference in days between each order's delivery date and the next order's placing date\n",
    "- The next order's placing date should be before the current order's delivery date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window: partition by 'customer_id', order by 'placing_date'\n",
    "window = Window.partitionBy('customer_id').orderBy('placing_date')\n",
    "\n",
    "(\n",
    "    df_orders_products\n",
    "    # Get the next order placing date for each order\n",
    "    .withColumn(\n",
    "        'next_placing_date',\n",
    "        f.lead('placing_date').over(window)\n",
    "    )\n",
    "    # Calculate the difference in days between the current\n",
    "    # order delivery date and next order placing date\n",
    "    .withColumn(\n",
    "        'days_diff',\n",
    "        f.datediff(f.col('delivery_date'), f.col('next_placing_date'))\n",
    "    )\n",
    "    # Filter the rows where the next order was placed before the current order was delivered\n",
    "    .filter(f.col('next_placing_date') < f.col('delivery_date'))\n",
    "    .select(\n",
    "        'customer_id',\n",
    "        'placing_date',\n",
    "        'delivery_date',\n",
    "        'next_placing_date',\n",
    "        'days_diff'\n",
    "    )\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is the yearly average profit increase or decrease (difference between year Y and year Y-1) for each supplier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get the average profit for each supplier in each year\n",
    "df_avg_profit = (\n",
    "    df_orders_products\n",
    "    .groupBy(['order_year', 'supplier_id'])\n",
    "    .agg(f.avg('profit').alias('avg_profit'))\n",
    ")\n",
    "\n",
    "df_avg_profit.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, define the window: partition by 'supplier_id', order by 'order_year'\n",
    "window = Window.partitionBy('supplier_id').orderBy('order_year')\n",
    "\n",
    "(\n",
    "    df_avg_profit\n",
    "    # Get the previous year average profit for each supplier\n",
    "    .withColumn('prev_year_avg_profit', f.lag('avg_profit').over(window))\n",
    "    # Calculate the difference between the average profit and the previous year average profit\n",
    "    .withColumn('profit_diff', f.col('avg_profit') - f.col('prev_year_avg_profit'))\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Determine the top 3 products with the highest profit margin.\n",
    "\n",
    "Profit margin refers to the ratio between profit and revenue:\n",
    "\n",
    "$profit\\_margin_{product} = profit_{product} / revenue_{product}$\n",
    "\n",
    "$profit_{product} = revenue_{product} - cost_{product}$\n",
    "\n",
    "So let's break this question down:\n",
    "- To calculate the cost of each product's order, we need to multiply the cost per unit by the quantity ordered\n",
    "- Then, we want to get the total revenue and total cost of each product, for each supplier country\n",
    "- Next, the profit is calculated as the difference between revenue and cost and the profit margin is calculated as the ratio between profit and revenue\n",
    "- Finally, we rank the products by profit margin and select the top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, calculate the total cost of each product order\n",
    "df_cost = (\n",
    "    df_orders_products\n",
    "    .withColumn('cost', f.col('amount') * f.col('cost_per_unit'))\n",
    ")\n",
    "\n",
    "df_cost.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, get the total cost and revenue of each product, for each supplier country\n",
    "df_grouped = (\n",
    "    df_cost\n",
    "    .groupBy(['supplier_country', 'product_id'])\n",
    "    .agg(\n",
    "        f.sum('cost').alias('total_cost'),\n",
    "        f.sum('revenue').alias('total_revenue')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_grouped.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, calculate the profit and profit margin for each product\n",
    "df_profit_margin = (   \n",
    "    df_grouped\n",
    "    # Calculate the profit\n",
    "    .withColumn('profit', f.col('total_revenue') - f.col('total_cost'))\n",
    "    # Calculate the profit margin\n",
    "    .withColumn('profit_margin', f.col('profit') / f.col('total_revenue'))\n",
    ")\n",
    "\n",
    "df_profit_margin.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, rank the products by profit margin\n",
    "\n",
    "# Define the window: partition by 'supplier_country', order by 'profit_margin' in descending order\n",
    "window = Window.partitionBy('supplier_country').orderBy(f.desc('profit_margin'))\n",
    "\n",
    "(\n",
    "    df_profit_margin\n",
    "    # Rank the products by their profit margin\n",
    "    .withColumn('rank', f.rank().over(window))\n",
    "    # Filter the top 3 products by profit margin\n",
    "    .filter(f.col('rank') <= 3)\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the whole solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_orders_products\n",
    "    # Calculate cost per order\n",
    "    .withColumn('cost', f.col('amount') * f.col('cost_per_unit'))\n",
    "    # Get total cost and revenue of each product, for each supplier country\n",
    "    .groupBy(['supplier_country', 'product_id'])\n",
    "    .agg(\n",
    "        f.sum('cost').alias('total_cost'),\n",
    "        f.sum('revenue').alias('total_revenue')\n",
    "    )\n",
    "    # Calculate the profit\n",
    "    .withColumn('profit', f.col('total_revenue') - f.col('total_cost'))\n",
    "    # Calculate the profit margin\n",
    "    .withColumn('profit_margin', f.col('profit') / f.col('total_revenue'))\n",
    "    # Rank the products by their profit margin\n",
    "    .withColumn('rank', f.rank().over(window))\n",
    "    # Filter the top 3 products by profit margin\n",
    "    .filter(f.col('rank') <= 3)\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **BONUS** Calculate the cumulative sum of average revenue generated by each customer over the years\n",
    "\n",
    "Hint: Check all Window methods and attributes [here](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Window.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (\n",
    "    Window\n",
    "    .partitionBy('customer_id')\n",
    "    .orderBy('order_year')\n",
    "    # Define the window frame: from the first year to the current year\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    ")\n",
    "\n",
    "(\n",
    "    df_orders_products\n",
    "    # Calculate the total revenue for each customer in each year\n",
    "    .groupBy('customer_id', 'order_year')\n",
    "    .agg(f.sum('revenue').alias('total_revenue'))\n",
    "    # Calculate the cumulative revenue for each customer over the years\n",
    "    .withColumn(\n",
    "        'cum_revenue',\n",
    "        f.sum('total_revenue').over(window)\n",
    "    )\n",
    ").display()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
